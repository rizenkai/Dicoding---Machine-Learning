# -*- coding: utf-8 -*-
"""[Klasifikasi] Submission Akhir BMLP_Mochamad Masdarul Anwar.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DJoX06G9BNcyfFg0WLHREMkbx306mdgk

# **1. Import Library**

Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning.
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score

"""# **2. Memuat Dataset dari Hasil Clustering**

Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame.
"""

df = pd.read_csv('/content/hasil_clustering.csv')
df

"""# **3. Data Splitting**

Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set).
"""

X = df.drop('Cluster', axis=1)
y = df['Cluster']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# **4. Membangun Model Klasifikasi**

## **a. Membangun Model Klasifikasi**

Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.

Berikut adalah rekomendasi tahapannya.
1. Pilih algoritma klasifikasi yang sesuai, seperti Logistic Regression, Decision Tree, Random Forest, atau K-Nearest Neighbors (KNN).
2. Latih model menggunakan data latih.
"""

models = {
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier(),
}

encoder = LabelEncoder()

for col in X_train.select_dtypes(include=['object']).columns:
    X_train[col] = encoder.fit_transform(X_train[col])
    X_test[col] = encoder.transform(X_test[col])

"""Tulis narasi atau penjelasan algoritma yang Anda gunakan.

## **b. Evaluasi Model Klasifikasi**

Berikut adalah **rekomendasi** tahapannya.
1. Lakukan prediksi menggunakan data uji.
2. Hitung metrik evaluasi seperti Accuracy dan F1-Score (Opsional: Precision dan Recall).
3. Buat confusion matrix untuk melihat detail prediksi benar dan salah.
"""

results = {}
for name, model in models.items():
    # Fit the model on the training data
    model.fit(X_train, y_train)

    # Predict the target variable for the test data
    y_pred = model.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    cm = confusion_matrix(y_test, y_pred)

    results[name] = {
        "accuracy": accuracy,
        "precision": precision,
        "recall": recall,
        "f1_score": f1,
        "confusion_matrix": cm
    }

    print(f"Hasil evaluasi model {name}:")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1-score: {f1:.4f}")
    print("Confusion Matrix:")
    print(cm)
    print("-" * 20)

"""Tulis hasil evaluasi algoritma yang digunakan, jika Anda menggunakan 2 algoritma, maka bandingkan hasilnya.

Berikut adalah hasil evaluasi dan perbandingan dua algoritma yang digunakan, yaitu **Decision Tree** dan **Random Forest**:

### 1. **Decision Tree**
- Accuracy: 0.9757
- Precision: 0.9753
- Recall: 0.9757
- F1-score: 0.9753


**Kelebihan Decision Tree**:
- Mudah diinterpretasi.
- Cepat dalam proses pelatihan, terutama untuk dataset kecil.
  
**Kekurangan Decision Tree**:
- Lebih rentan terhadap overfitting.
- Kurang stabil terhadap perubahan data kecil.

---

### 2. **Random Forest**
- Accuracy: 0.9853
- Precision: 0.9853
- Recall: 0.9853
- F1-score: 0.9851


**Kelebihan Random Forest**:
- Lebih akurat dibanding Decision Tree karena menggunakan teknik ensemble.
- Tahan terhadap overfitting dengan melakukan rata-rata prediksi beberapa pohon.

**Kekurangan Random Forest**:
- Waktu pelatihan lebih lama dibanding Decision Tree.
- Sulit diinterpretasi karena melibatkan banyak pohon.

---


Dari hasil evaluasi, **Random Forest** memberikan performa yang lebih baik dibandingkan dengan **Decision Tree** pada semua metrik evaluasi. Hal ini menunjukkan bahwa Random Forest lebih andal dalam menangani dataset dengan kompleksitas lebih tinggi dan mampu mengurangi risiko overfitting.

## **c. Tuning Model Klasifikasi (Optional)**

Gunakan GridSearchCV, RandomizedSearchCV, atau metode lainnya untuk mencari kombinasi hyperparameter terbaik
"""

#Type your code here

"""## **d. Evaluasi Model Klasifikasi setelah Tuning (Optional)**

Berikut adalah rekomendasi tahapannya.
1. Gunakan model dengan hyperparameter terbaik.
2. Hitung ulang metrik evaluasi untuk melihat apakah ada peningkatan performa.
"""

#Type your code here

"""## **e. Analisis Hasil Evaluasi Model Klasifikasi**

### **1. Identifikasi Model**
Berdasarkan hasil evaluasi yang telah dilakukan, kita dapat menganalisis metrik dan hasil confusion matrix dari **Decision Tree** dan **Random Forest**:

#### **Precision, Recall, dan F1-Score**
- **Decision Tree**:
  - Accuracy: 0.9757
  - Precision: 0.9753
  - Recall: 0.9757
  - F1-score: 0.9753
- **Random Forest**:
  - Accuracy: 0.9853
  - Precision: 0.9853
  - Recall: 0.9853
  - F1-score: 0.9851

Semua metrik menunjukkan performa yang sangat baik untuk kedua model. Nilai precision, recall, dan F1-score yang tinggi mengindikasikan bahwa kedua model bekerja dengan baik dalam mengklasifikasikan data. Namun, perlu diperhatikan bahwa **Random Forest** sedikit lebih unggul dibandingkan dengan **Decision Tree**.




- **Temuan**:
  - Secara umum, kedua model menunjukkan performa yang baik, dengan hanya sedikit kesalahan di beberapa kelas. Misalnya, **kelas 5** dan **kelas 8** memiliki beberapa **False Positives** dan **False Negatives** yang menunjukkan adanya kesalahan klasifikasi pada kelas-kelas tersebut.
  - Tidak ada prediksi positif yang signifikan untuk kelas minoritas di beberapa kasus. Ini mengindikasikan bahwa ada kemungkinan ketidakseimbangan kelas pada dataset.

---

### **2. Analisis Fitting**
#### **Overfitting**
- **Decision Tree** mungkin mengalami **overfitting**, terutama jika pohon terlalu dalam dan model hanya menyesuaikan diri dengan data pelatihan, meskipun hasil confusion matrix menunjukkan performa yang baik. Random Forest cenderung lebih robust terhadap overfitting karena menggunakan banyak pohon dan menggabungkan hasilnya.

#### **Underfitting**
- Tidak ada indikasi **underfitting** pada kedua model, karena metrik evaluasi yang sangat tinggi menunjukkan bahwa model telah belajar dengan baik dari data dan menangkap pola yang relevan.

---

### **3. Rekomendasi Tindakan Lanjutan**

Berdasarkan hasil analisis, berikut adalah beberapa rekomendasi untuk langkah selanjutnya:

#### **a. Validasi Model dengan Cross-Validation**
- Disarankan untuk menggunakan **k-fold cross-validation** untuk memastikan bahwa performa model konsisten pada seluruh dataset. Hal ini akan membantu mengurangi bias akibat pembagian data yang tidak representatif.

#### **b. Analisis Dataset**
- **Ketidakseimbangan Kelas**: Karena kita melihat bahwa beberapa kelas minoritas memiliki masalah dalam prediksi (misalnya, kelas 5 dan kelas 8), disarankan untuk menerapkan teknik penanganan ketidakseimbangan kelas. Beberapa teknik yang dapat diterapkan adalah:
  - **Oversampling (SMOTE)** pada kelas minoritas.
  - **Undersampling** pada kelas mayoritas.
  - Menyesuaikan **class-weight** pada model untuk memberi bobot lebih besar pada kelas yang kurang terwakili.
  
- **Distribusi Data**: Analisis distribusi data untuk setiap fitur dan kelas sangat penting untuk memastikan bahwa dataset cukup representatif terhadap masalah dunia nyata. Jika ada ketidakseimbangan atau kesalahan dalam distribusi data, perlu dilakukan penyesuaian pada dataset.

#### **c. Eksperimen dengan Dataset yang Lebih Kompleks**
- Jika dataset terlalu sederhana, pertimbangkan untuk **memperluas dataset** dengan data baru atau data yang lebih bervariasi. Dataset yang lebih kompleks dan beragam akan lebih mencerminkan dunia nyata dan meningkatkan kemampuan generalisasi model.

#### **d. Coba Algoritma dan Pendekatan Lain**
- Selain **Decision Tree** dan **Random Forest**, kita juga bisa mencoba algoritma lain seperti:
  - **Logistic Regression** untuk klasifikasi linier.
  - **SVM (Support Vector Machine)**, yang sering kali memberikan hasil yang baik pada masalah klasifikasi.
  - **Ensemble methods** seperti **XGBoost** atau **LightGBM**, yang dapat mengatasi ketidakseimbangan kelas dan meningkatkan akurasi model secara keseluruhan.

#### **e. Tuning Hyperparameter**
- Gunakan **grid search** atau **random search** untuk mencari kombinasi hyperparameter terbaik, terutama pada **Random Forest** dan **K-Nearest Neighbors**. Hyperparameter seperti jumlah pohon (n_estimators) dan kedalaman pohon (max_depth) pada Random Forest, serta jumlah tetangga (n_neighbors) pada KNN, dapat mempengaruhi performa model secara signifikan.

#### **f. Evaluasi dengan Data Baru**
- Jika memungkinkan, **uji model dengan dataset eksternal** atau data baru untuk menguji kemampuannya dalam **generalize** pada data yang tidak terlihat sebelumnya. Ini akan memberi gambaran yang lebih jelas tentang kinerja model dalam situasi dunia nyata.

#### **g. Tambahkan Metrik Evaluasi Lain**
- Selain **Precision**, **Recall**, dan **F1-Score**, kami juga menyarankan untuk menggunakan metrik evaluasi tambahan seperti **ROC-AUC** atau **PR-AUC** (Precision-Recall AUC). Metrik ini sangat berguna, terutama pada dataset yang tidak seimbang, karena dapat memberikan gambaran yang lebih jelas tentang performa model pada seluruh distribusi kelas.

---
"""