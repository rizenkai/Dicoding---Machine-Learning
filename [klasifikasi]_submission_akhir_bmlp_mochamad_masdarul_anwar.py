# -*- coding: utf-8 -*-
"""[Klasifikasi] Submission Akhir BMLP_Mochamad Masdarul Anwar.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13jDMV5S4v8EFQhfYMeqtGTtCQlQ4Rm9X

# **1. Import Library**

Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning.
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score

"""# **2. Memuat Dataset dari Hasil Clustering**

Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame.
"""

df = pd.read_csv('/content/hasil_clustering.csv')
df

"""# **3. Data Splitting**

Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set).
"""

X = df.drop('Cluster', axis=1)
y = df['Cluster']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# **4. Membangun Model Klasifikasi**

## **a. Membangun Model Klasifikasi**

Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.

Berikut adalah rekomendasi tahapannya.
1. Pilih algoritma klasifikasi yang sesuai, seperti Logistic Regression, Decision Tree, Random Forest, atau K-Nearest Neighbors (KNN).
2. Latih model menggunakan data latih.
"""

models = {
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier(),
    "K-Nearest Neighbors": KNeighborsClassifier(),
}

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

"""Tulis narasi atau penjelasan algoritma yang Anda gunakan.

## **b. Evaluasi Model Klasifikasi**

Berikut adalah **rekomendasi** tahapannya.
1. Lakukan prediksi menggunakan data uji.
2. Hitung metrik evaluasi seperti Accuracy dan F1-Score (Opsional: Precision dan Recall).
3. Buat confusion matrix untuk melihat detail prediksi benar dan salah.

Tulis hasil evaluasi algoritma yang digunakan, jika Anda menggunakan 2 algoritma, maka bandingkan hasilnya.
"""

results = {}
for name, model in models.items():
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    cm = confusion_matrix(y_test, y_pred)

    results[name] = {
        "accuracy": accuracy,
        "precision": precision,
        "recall": recall,
        "f1_score": f1,
        "confusion_matrix": cm
    }

    print(f"Hasil evaluasi model {name}:")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1-score: {f1:.4f}")
    print("Confusion Matrix:")
    print(cm)
    print("-" * 20)

"""## **c. Tuning Model Klasifikasi (Optional)**

Gunakan GridSearchCV, RandomizedSearchCV, atau metode lainnya untuk mencari kombinasi hyperparameter terbaik
"""

#Type your code here

"""## **d. Evaluasi Model Klasifikasi setelah Tuning (Optional)**

Berikut adalah rekomendasi tahapannya.
1. Gunakan model dengan hyperparameter terbaik.
2. Hitung ulang metrik evaluasi untuk melihat apakah ada peningkatan performa.
"""

#Type your code here

"""## **e. Analisis Hasil Evaluasi Model Klasifikasi**

**1. Identifikasi Model**
- **Precision, Recall, dan F1-Score**: Semua metrik menunjukkan nilai yang sangat tinggi (Precision: 0.9900, Recall: 0.9950, F1-Score: 0.9925) untuk ketiga algoritma (Decision Tree, Random Forest, dan K-Nearest Neighbors).
  - Ini mengindikasikan performa yang sangat baik, tetapi terdapat potensi anomali karena hasil confusion matrix tidak menunjukkan adanya prediksi positif yang benar (True Positive = 0).
- **Confusion Matrix**: Semua model menghasilkan confusion matrix yang sama:
  ```
  [[199   0]
   [  1   0]]
  ```
  - **Temuan**:
    - Model tidak pernah memprediksi kelas positif (kelas minoritas).
    - Hal ini dapat terjadi karena ketidakseimbangan kelas (class imbalance) yang menyebabkan model lebih condong ke kelas mayoritas.

**2. Analisis Fitting**
- **Overfitting**:
  - Tidak terlihat indikasi overfitting secara langsung karena metrik evaluasi pada data uji cukup konsisten. Namun, performa yang sangat mirip untuk ketiga model dapat mengindikasikan bahwa dataset terlalu sederhana atau tidak mencerminkan kompleksitas dunia nyata.
- **Underfitting**:
  - Tidak teridentifikasi, karena metrik evaluasi sangat tinggi. Ini menunjukkan bahwa model mampu menangkap pola pada dataset dengan baik.

---

**3. Rekomendasi Tindakan Lanjutan**

**a. Validasi Model dengan Cross-Validation**
- Gunakan teknik k-fold cross-validation untuk memastikan performa model konsisten pada seluruh dataset dan menghindari hasil yang bias dari pembagian data.

**b. Analisis Dataset**
- **Ketidakseimbangan Kelas**: Jika jumlah data pada kelas positif sangat sedikit, pertimbangkan untuk menggunakan metode seperti oversampling (SMOTE), undersampling, atau pemberian bobot lebih besar pada kelas minoritas.
- **Distribusi Data**: Analisis distribusi data untuk setiap fitur dan kelas untuk memastikan dataset cukup representatif terhadap masalah dunia nyata.

**c. Eksperimen dengan Dataset yang Lebih Kompleks**
- Jika dataset terlalu sederhana, pertimbangkan untuk memperluas dataset dengan data baru atau lebih bervariasi yang mencerminkan kompleksitas kasus sebenarnya.

**d. Coba Algoritma dan Pendekatan Lain**
- Eksperimen dengan algoritma lain seperti Logistic Regression, SVM, atau ensemble learning seperti XGBoost dan LightGBM untuk membandingkan performa model.

**e. Tuning Hyperparameter**
- Gunakan grid search atau random search untuk mencari kombinasi hyperparameter terbaik, terutama untuk Random Forest dan KNN.

**f. Evaluasi dengan Data Baru**
- Jika memungkinkan, uji model dengan dataset eksternal atau data baru untuk mengevaluasi kemampuan generalisasi model terhadap data yang tidak terlihat sebelumnya.

**g. Tambahkan Metrik Evaluasi Lain**
- Gunakan metrik seperti ROC-AUC atau PR-AUC untuk memberikan pandangan yang lebih baik terhadap performa model, khususnya pada dataset yang tidak seimbang.

---
"""